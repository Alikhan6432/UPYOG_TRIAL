{"version":3,"sources":["../../src/kafka/consumer.js"],"names":["kafka","require","listenConsumer","topic","receiveJob","Consumer","client","KafkaClient","kafkaHost","envVariables","KAFKA_BROKER_HOST","topicList","i","push","consumer","autoCommit","on","logger","info","message","data","JSON","parse","value","then","catch","error","stack","err"],"mappings":";;;;;;;;;;;;;;;AACA;;;;AACA;;;;AACA;;;;AAHA,IAAMA,QAAQC,QAAQ,YAAR,CAAd;AAMO,IAAMC;AAAA,sFAAiB,iBAAMC,KAAN;AAAA;AAAA;AAAA;AAAA;AAAA;AAC9B;AACIC,sBAF0B,GAEbD,KAFa;AAKxBE,oBALwB,GAKbL,MAAMK,QALO;AAM1BC,kBAN0B,GAMjB,IAAIN,MAAMO,WAAV,CAAsB;AACjCC,yBAAWC,+BAAaC;AADS,aAAtB,CANiB;AAW1BC,qBAX0B,GAWd,EAXc;;AAY9B,iBAASC,CAAT,IAAcR,UAAd,EAA0B;AACxBO,wBAAUE,IAAV,CAAe,EAACV,OAAOC,WAAWQ,CAAX,CAAR,EAAf;AACD;;AAEKE,oBAhBwB,GAgBb,IAAIT,QAAJ,CAAaC,MAAb,EAAqBK,SAArB,EAAgC;;AAE/CI,0BAAY;AAFmC,aAAhC,CAhBa;;;AAqB9BD,qBAASE,EAAT,CAAY,OAAZ,EAAqB,YAAW;AAC9BC,+BAAOC,IAAP,CAAY,mBAAZ;AACD,aAFD;;AAIAJ,qBAASE,EAAT,CAAY,SAAZ,EAAuB,UAASG,OAAT,EAAkB;AACvCF,+BAAOC,IAAP,CAAY,wCAAZ;AACA,kBAAI;AACF,oBAAIE,OAAOC,KAAKC,KAAL,CAAWH,QAAQI,KAAnB,CAAX;AACAH,qBAAKjB,KAAL,GAAagB,QAAQhB,KAArB;AACA,0CACEiB,IADF,EAEE,IAFF,EAGE,YAAM,CAAE,CAHV,EAIE,YAAM,CAAE,CAJV,EAMGI,IANH,CAMQ,YAAM;AACVP,mCAAOC,IAAP,CAAY,qCAAZ;AACD,iBARH,EASGO,KATH,CASS,iBAAS;AACdR,mCAAOS,KAAP,CAAaA,MAAMC,KAAN,IAAeD,KAA5B;AACD,iBAXH;AAYD,eAfD,CAeE,OAAOA,KAAP,EAAc;AACdT,iCAAOS,KAAP,CAAa,yCAAyCA,MAAMP,OAA5D;AACAF,iCAAOS,KAAP,CAAaA,MAAMC,KAAN,IAAeD,KAA5B;AACD;AACF,aArBD;;AAuBAZ,qBAASE,EAAT,CAAY,OAAZ,EAAqB,UAASY,GAAT,EAAc;AACjCX,+BAAOS,KAAP,CAAa,uBAAuBE,IAAIT,OAAxC;AACAF,+BAAOS,KAAP,CAAaE,IAAID,KAAJ,IAAaC,GAA1B;AACD,aAHD;;AAKAd,qBAASE,EAAT,CAAY,kBAAZ,EAAgC,UAASY,GAAT,EAAc;AAC5CX,+BAAOS,KAAP,CAAa,kBAAb;AACAT,+BAAOS,KAAP,CAAaE,IAAID,KAAJ,IAAaC,GAA1B;AACD,aAHD;;AArD8B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAAjB;;AAAA;AAAA;AAAA;AAAA,GAAN","file":"consumer.js","sourcesContent":["const kafka = require(\"kafka-node\");\nimport envVariables from \"../EnvironmentVariables\";\nimport logger from \"../config/logger\";\nimport { createAndSave } from \"../index\";\n\n\nexport const listenConsumer = async(topic)=>{\n//let receiveJob = envVariables.KAFKA_RECEIVE_CREATE_JOB_TOPIC;\nlet receiveJob = topic;\n\n\nconst Consumer = kafka.Consumer;\nlet client = new kafka.KafkaClient({\n  kafkaHost: envVariables.KAFKA_BROKER_HOST\n});\n\n\nvar topicList = [];\nfor (var i in receiveJob) {\n  topicList.push({topic: receiveJob[i]});\n}\n\nconst consumer = new Consumer(client, topicList, {\n\n  autoCommit: false\n});\n\nconsumer.on(\"ready\", function() {\n  logger.info(\"consumer is ready\");\n});\n\nconsumer.on(\"message\", function(message) {\n  logger.info(\"record received on consumer for create\");\n  try {\n    var data = JSON.parse(message.value);\n    data.topic = message.topic;\n    createAndSave(\n      data,\n      null,\n      () => {},\n      () => {}\n    )\n      .then(() => {\n        logger.info(\"record created for consumer request\");\n      })\n      .catch(error => {\n        logger.error(error.stack || error);\n      });\n  } catch (error) {\n    logger.error(\"error in create request by consumer \" + error.message);\n    logger.error(error.stack || error);\n  }\n});\n\nconsumer.on(\"error\", function(err) {\n  logger.error(\"error in consumer \" + err.message);\n  logger.error(err.stack || err);\n});\n\nconsumer.on(\"offsetOutOfRange\", function(err) {\n  logger.error(\"offsetOutOfRange\");\n  logger.error(err.stack || err);\n});\n\n}\n\n"]}